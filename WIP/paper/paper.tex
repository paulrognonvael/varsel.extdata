\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\title{Improving variable selection properties with transfer learning and data integration}
\author{Paul Rognon-Vael}
\date{October 2025}

\begin{document}

\maketitle
We study how variable selection properties can be improved by leveraging external information 
on the likelihood of variables to be truly associated to the outcome. As a particular case we consider 
a flexible transfer learning framework where the set of variable selected in the source is transferred to 
ease variable selection in the target. We introduce a family of penalized linear regression methods where 
the penalties depend on the external information or transferred set of variables and are motivated by 
connections to Bayesian variable selection. We develop a careful analysis of the fundamental limits on 
consistent variable selection in linear regression and show that these can be pushed with external data 
and transfer learning. We first precisely quantify the gains that are achievable for ideal penalties set by an oracle. 
Subsequently, we propose computationally fast algorithms for the incorporation of external information and transfer 
learning that are inspired by empirical Bayes techniques and do not require an oracle. We prove these algorithms 
recover most of the gains achievable by oracle penalties and are robust to negative transfer. We show the proposed algorithm improves on standard methods
on simulated and empirical data.

\paul{}

\section{Introduction}

In a data-rich world, basing statistical inference on only a single source of information increasingly seems like a missed opportunity. As ever more data is being generated and stored, many have answered statistical questions by 
leveraging multiple datasets. Integrating multiple sources of data implies handling and possibly exploiting some form of heterogeneity. There may be heterogeneity in samples where, for example, samples are not identically distributed but rather feature a group structure XXX cite some Annie Qu's work XXX. There may also be heterogeneity in variables in which case there is often knowledge, external to the dataset of interest, of varying likelihood of variables to be truly associated to the outcome of interest. This may occur when working with \textit{multimodal} data, i.e. featuring different types of variables \cite{}, where one block of variables may be expected to be less sparse than another, e.g. clinical vs genomic markers. Another example is when meta-data is available on the variables themselves, e.g functional annotations on genes. A setting of particular interest is transfer learning which %has attracted a lot of attention lately \cite{} and 
can broadly be defined as the problem of improving learning for given \textit{target} task and dataset by reusing knowledge acquired from similar \textit{source} tasks and datasets. In that case, the set of variable selected in the source data and task may be seen as external knowledge on the likelihood of variables to be truly associated to the target outcome. Other problems, closely related to transfer learning, may involve similar knowledge:
\textit{domain adaptation} concerned with adapting a model when applying to data which distribution differ from that of the training data and \textit{meta-learning} where a model is trained using information obtained
from other models with different architectures. For convenience, we refer to the different kinds of external knowledge on the likelihood of variables to be truly associated to the outcome as external information.   

In high-dimensional settings, where the number of samples is smaller than the number of parameters, leveraging such 
external information is a particularly attractive idea. The inherent scarcity of information of these settings implies that strong assumptions are required to carry out meaningful inference. In structural learning problems such as variable selection, those assumptions regard sparsity and signal strength and, although mathematically necessary, they can be too strong in practice 
(see \citep{giannone2021economic} for a discussion in the context of social sciences). Numerous applied and methodological works have employed such external information to guide structural learning and consistently observed improvements when suitable external information is integrated. bousteleix..., codata,... As regards transfer learning, statistical literature has focused on the transfer from the source to the target of parameter estimates. Some proposed methods perform variable selection but do not consider the transfer of the set of selected variables as we consider here.  perform variable selection example telesca.


Despite empirical success, a theoretical framework explaining precisely why and how leveraging external information on the likelihood of variables to be truly associated to the outcome as possible with data integration and transfer learning is not currently available. In this work, we investigate how, in linear regression, said information allows pushing the mathematical conditions under which consistently recovering the true subset of variables associated to the outcome is possible, and improving the corresponding rates. Consistency is understood here as recovering the true subset with probability going to 1 as the number of samples $n$ and possibly the dimension $p$ go to infinity. 

To make ideas concrete, consider variable selection in the Gaussian linear regression
\begin{equation}\label{eq:linearmodel}
	\bs y \;=\; \bs X \bs \beta^* + \bs\epsilon,\qquad \bs \epsilon \sim N(0,\sigma^2 I_n),
\end{equation}
where $\bs X\in \R^{n\times p}$, $\bs y\in \R^n$, $\sigma >0$, and $\bs \beta \in \mathbb{R}^p$ are the data-generating parameters. A large class of methods operate by penalizing the size of an estimated $\hat{\bs  \beta}$. For instance, penalized likelihood methods optimize the log-likelihood plus a penalty term driven by the $\ell_q$ "norm" of $\hat{\bs  \beta}$ for $q\in [0,1]$ \citep{lasso,bertsimas}. In particular, $\ell_0$ penalties have been shown to have theoretically superior or even optimal selection properties \cite{infotheowainwright, XXXbyon} and to outperform other types of penalties in practice \cite{mazumder2020}. Advances in optimization and MCMC methods have also made $\ell_0$ penalized regression much more computationally tractable: it can be solved exactly for $p$ in the thousands \citep{bertsimas2020sparse} and with probability going to 1 with linear cost in $p$ using Markov Chain Monte Carlo (MCMC) under mild conditions \citep{Yang2016,zhou2022}. There is also a direct connection between $\ell_0$ penalties and Bayesian variable selection based on posterior model probabilities \citep{BIC,EBIC,rossell2022concentration}. Under mild regularity conditions, a choice of $\ell_0$ penalty corresponds to a choice of prior probability for the inclusion of variables in the support of $\bs \beta^*$. This connection is more formally discussed in Section \ref{sec:intro_blockpen}. Motivated by the superior properties and the convenient Bayesian interpretation of $\ell_0$ penalties, we study a class of $\ell_0$ penalties that depend on external information.

Indeed, the external information may be seen as providing prior knowledge in a Bayesian setting. The Bayesian framework has indeed been frequently observed to be naturally suited for transfer learning \cite{telesca, dunson...}. In such Bayesian setting, prior knowledge on the likelihood of variables to be associated with the outcome would be reflected in the choice of prior probability for their inclusion in the support of $\bs \beta^*$. Given the connection between those probabilities and $\ell_0$ penalties, in a frequentist setting, it is natural to let $\ell_0$ penalties depend on external information. Consider, for example, the transfer learning problem for the task of variable selection. Among the candidates variables in the target dataset, one can form two blocks: a first one with the variables that were also selected the source datasets and a second one with the rest of the variables. The external information induces here a partition in two blocks where, if the transfer is informative for selection in the target, there is prior knowledge that the first block is less sparse than the second.

More generally, assume that we have a vector of external information $\bs Z=(z_1,\ldots,z_p) \in \R^q$, where $z_i$ is the external information for variable $i=1,\ldots,p$, that partitions the $p$ variables into $b$ blocks $B_j \subset \{1,\ldots,p\}$, $j=1,\ldots,b$ so that key characteristics are thought to potentially vary across the $B_j$'s. That is, external information that induces a partition function 
\begin{equation}\label{eq:partition}
    \Gamma: z_i \to B_j \in \{1,...b\}.
\end{equation}
This framework encompasses, for example, the earlier transfer learning setting, the multimodal data setting with blocks given by the different types of variables and setting of the meta-data on variables with a single discrete meta-variable. We study here $\ell_0$ penalties that depend on such external information $\bs Z$ through the induced partition. More precisely, we consider $\ell_0$ penalties that allow modulating the strength of the penalty in each block. Unlike standard $\ell_0$ penalties, such as BIC \citep{BIC} or EBIC \citep{EBIC}, informed penalties are \textit{non-exchangeable} in the sense that the penalty for adding a variable $i$ can depend on its block $B_j=B_j(z_i)$. We derive the variable selection properties of those informed $\ell_0$ penalties and compare them to those of standard $\ell_0$ penalties in relation to the relevance of the external information or transfer.

\subsection{Notation}

The parameters of interest are denoted by $\bs \beta\in \R^p$  
and $\bs \beta^*$ denotes their true values. The set of variable indices is $V=\{1,\ldots,p\}$. For any $A\subseteq V$ and any vector $\bs x\in \R^p$, $\bs x_A$ denotes the subvector of $\bs x$ with entries corresponding to indices in $A$. For any matrix $\bs X \in \R^{n\times p}$, $\bs X_A$ denotes the submatrix of $\bs X$ obtained by selecting the \emph{columns} with indices in $A$. $S=\left\{i\in V:\,\,  \beta^*_i \neq 0 \right\}$ denotes the true support of $\bs \beta^*$, its size is $s=|S|$, and hence $p-s$ is the number of truly inactive parameters. The set of candidate models is denoted by $\M$ and is given by subsets $M\subseteq V$. Denote by $\beta_{\min}^*=\min_{i \in S}|\beta^*_i|$ the smallest true signal. The set $V$ is partitioned into blocks, their number is fixed and noted $b$. The blocks are disjoint and noted $B_j \subseteq V$ for $j=1,\ldots,b$. $S_j=\left\{i\in B_j:\,\,  \beta^*_i \neq 0\right\}$ denotes the set of active parameters in block $B_j$, $s_j=|S_j|$ its size, $p_j-s_j$ the number of inactive parameters in the block,
and $\beta_{\min,j}^*=\min_{i \in S_j}|\beta^*_i|$.

Given sequences $f(n) > 0$ and $g(n) >0$, $f(n)=O(g(n))$ means that there exists a constant $c<\infty$ such that $f(n) \leq c g(n)$ for all $n \geq n_0$ and some fixed $n_0$, $f(n)=o(g(n))$ means that $\lim_{n\to\infty}f(n)/g(n)=0$, and $f(n)=\Theta(g(n))$ means that $f(n) = O(g(n))$ and $g(n) = O(f(n))$. For any set $A$, $A^C$ denotes the complement of $A$.

\subsection{Related literature}

External information has been used to guide variable selection in many applications. For instance, in Bayesian literature, \cite{stingo:2011} and \cite{cassese:2014} proposed Bayesian variable selection methods for gene expression, where prior inclusion probabilities depend on biological knowledge and meta-variables. \cite{vandeWiel2019} similarly considers a regression of prior inclusion probabilities on external data and suggest an empirical Bayes approach to learn the regression parameter. \cite{Velten2021} proposed a variational Bayes approximation for the same setting. Recently \cite{busatto2023} considered a horseshoe type of prior that depends on external information. Beyond regression, node and edge variables have been incorporated in \cite{peterson} and \cite{jewson2023graphical} to drive edge inclusion in Gaussian graphical models, while \cite{schiavon2022generalized} used meta-variables to determine non-zero loadings in factor models. In the frequentist literature, \citet{Bergersen2011} proposed an $\ell_1$ penalty for linear regression on gene expression where the penalty varies depending on correlation between the gene expression and its copy number. In the context of multi-omics data, \cite{Boulesteix2017} let the $\ell_1$ penalty vary depending on the modality the variable belongs to. \cite{chen_tinghuei:2021} predicted disease outcomes by allowing LASSO penalties to depend on functional annotation categories. \cite{Zeng2020} and \cite{vanNee2023} proposed empirical Bayes approaches to setting for externally-informed $\ell_1$ and elastic-net penalties respectively. See \cite{vandewiel2024} for a complete review. Also related is the causal analysis literature were the inclusion of control variables may be driven by their degree of association with the variables of interest (referred to as treatments) \citep{belloni2014inference,antonelli2021bayesian}. 

The statistical properties of the transfer of parameter estimates in linear regression have previously been studied in different works. In the frequentist literature \cite{Jiang2016} proposed a variation of LASSO, the prior LASSO, where the $\ell_1$ penalization is supplemented by a penalization on the distance to the predicted values in the source datasets. They show improvements over LASSO in the efficiency in estimation and prediction. \cite{Li2021} proposed the Trans-LASSO to transfer parameter estimates in linear regression, where deviations from parameter estimates in source datasets are penalized. They show improvements over LASSO in optimal rates of convergence for prediction and estimation. In concurrent works, \cite{Li2024} and \cite{Tian2023} both extended Trans-LASSO to generalized linear models. In the Bayesian literature,  . We refer to \cite{dunson} for a more compete review of Bayesian literature on transfer learning.


\subsection{Organization and contribution}
The rest of the paper is organized as follows. In Section~{sec:intro_blockpen} we formally introduce externally-informed $\ell_0$ penalties and further detail their connection to Bayesian variable selection. We also describe the general assumptions used across results. Section~\ref{sec:properties_legression} studies the properties of external information-dependent, block-based, $\ell_0$ penalties and how they ease consistent model recovery. We show that an oracle, knowing the true pattern of sparsity and signal strength, may take advantage of the external information so that variable selection consistency is either attained where otherwise it would not be possible, or is attained at a faster rate. These oracle results give an understanding of the maximum gains achievable by leveraging external information. Results are tight, when applied to standard $\ell_0$ penalties with no access to external information, they match the minimax results of \cite{Bunea2007} under orthogonal design and match or improve the results on the fundamental limits on variable selection \cite{infotheowainwright, wang2010, bryon}. 

In Section XXX, we propose a two-step data-based procedure grounded in empirical Bayes methods to set externally-informed $\ell_0$ penalties. We show the proposed procedure improves variable selection properties without requiring an oracle and compare its properties to those of oracle-set penalties. As a particular case, we discuss the properties of a transfer learning algorithm for the transfer of the set of selected variables from the source to the target. In particular, we show it is robust to so-called \textit{negative transfer}, when used transfer learning worsens the performance in the target. To the best of our knowledge, this is the first theoretical analysis of such transfer learning algorithm centered on the transfer of the binary information of selection vs. no selection in source, rather than parameter estimates. This is relevant firstly because the transfer of selection information might be preferred when the similarity between source and target data is thought to lie in the sets of variables associated to the respective outcomes, rather than in the distance between respective parameter vectors. Secondly, our work highlights the value of transferring the set of selected variables independently of parameter estimates. Our transfer learning algorithm is also highly flexible as it does not require full access to the source data, nor that the source task is a linear regression, nor that the set of variables is the same between the source and the target data.

\end{document}
